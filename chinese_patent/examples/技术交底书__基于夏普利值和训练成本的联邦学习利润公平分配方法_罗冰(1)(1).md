# 技术交底书__基于夏普利值和训练成本的联邦学习利润公平分配方法_罗冰(1)(1)

## 1、详细介绍技术背景，并描述已有的与本发明相关的现有技术，说明现有技术的缺点
<!-- 撰写指导：
只写与本发明有关的技术背景以及现有技术、现有技术的缺点。 -->

在大数据时代，公司或机构可通过用户提供的海量数据进行价值模型的机器学习，并利用此模型获得丰厚利益。随着国家对数据隐私保护越发重视，传统的将所有用户数据汇聚到中心训练端的机器学习范式将不再合规，一种保护隐私的分布式机器学习范式-联邦学习获得了大量关注。联邦学习不需将用户数据集中，暴露在中心训练端，参与方只需反复进行本地模型训练，将模型参数发送给中心端直至收敛即可完成训练。为了促使不同公司或用户能够有意愿加入联邦学习来合作训练模型，并激励其在提供训练数据的基础上，进一步提供电力和时间成本进行本地模型训练，急需一种有效衡量参与方数据贡献程度和能够补偿本地资源成本消耗的方法，并进一步设计符合市场经济学运行规律的利润分配机制，来将模型所得利润公平有效分配给联邦学习的参与方，从而有效激励参与方加入联邦学习，避免因分配不均而导致参与方放弃参与联邦学习。
然而，现有联邦学习专利，如CN113762530A，仅关注联邦学习模型的训练方式和保护隐私的具体策略，缺乏对联邦学习参与方贡献衡量方法的探究。已有的评估联邦学习参与方贡献度的专利，如CN112949865A，仅通过参与方模型的梯度信息来衡量贡献大小，无法有效满足不同参与方之间的公平性。现有专利如CN111461341A，虽然利用经济学原理中公平衡量贡献的夏普利值方法来衡量机器学习中各方数据源贡献度，却无法体现及补偿联邦学习中用户本地模型训练所消耗的资源成本消耗如电能和时间等成本。此外，对于面向用户设备（cross-device）的联邦学习场景，由于受通信带宽和计算资源等限制，无法确保所有用户设备每轮都参与联邦学习，因此缺乏针对该联邦学习场景下的数据价值公平衡量方法。

## 2、本发明摘要：针对现有技术存在的技术问题，提出本发明的基本方案或基本思路，以及本发明针对现有技术所具备的整体技术效果
<!-- 撰写指导：
不必描述实施细节，概括说明本发明的方案或思路，并说明由这种方案能带来的技术效果。 -->

本发明针对传统联邦学习的利润分配机制缺乏符合经济学原理和符合市场运行规律的利润分配机制问题，提出并公开了一种基于改进夏普利值来衡量参与方数据价值和参与方本地训练资源成本消耗的联邦学习模型利润公平分配方法。本分配方案的核心思想是：首次将夏普利值应用于联邦学习利润分配方案设计，提出基于合作博弈中的夏普利值方法来公平地衡量联邦学习参与方的数据价值。具体的，所发明的改进夏普利值计算方法针对现有两类联邦学习场景：（1）面向移动用户或物联网设备的联邦学习，其参与方（cross-device）受通信带宽和计算资源等限制无法每轮全部参与联邦学习（2）面向公司机构的联邦学习，其参与方(cross-silo)可以稳定的每轮参与联邦学习，分别设计了公平有效的衡量参与方在联邦学习过程中贡献的计算方法。此外，所发明的分配方案进一步考虑了联邦学习特有的参与方同时贡献本地模型训练的资源成本，使得所设计的联邦学习利益分配机制更能体现利润分配的公平性，从而有效激励各参与方加入联邦。

## 3、本发明技术方案的详细阐述，应该结合机械图、流程图、原理框图、电路图、时序图进行说明
<!-- 撰写指导：
3．1、充分说明本发明每一个详细技术方案，
3．2、本发明技术方案带来的效果的详细描述，不仅要说明本发明整体能带来的效果，而且由于某些技术特征可以直接导致的技术效果，也应该在这里结合技术特征的说明来描述效果；
3．3、充分说明所有可以实现本发明的实施方式，主要从实现本发明的细节角度考虑是否有相类似的方式方法或者其他变形的方法，如果有，则请列出。 -->

本发明的主要目的是提供一种基于夏普利值和训练成本的公平的联邦学习利润分配方法。其主要特点是利用夏普利值来衡量参与方（包括面向公司机构和用户设备）的数据贡献度，并考虑联邦学习参与方在本地模型训练时贡献的资源成本，实现公平地分配联邦学习模型获得的利润。为实现上述目的，本发明的技术方法如下，流程图描述见图4：
（1）针对联邦学习参与方的不同类别，本发明将联邦学习划分为面向公司机构的联邦学习和面向移动用户或物联网设备的联邦学习两种应用场景。
（2.1）若为公司（或机构）参与的联邦学习场景，计算某家公司 提供的数据价值即夏普利值的方法文字描述如下文（2.1.1）-（2.1.6）所示，流程图描述见图2。
（2.1.1）将此公司与联邦学习大联盟内的任意其他一个或多个公司（记为 ）组成一个小联盟，记为 ,利用联邦学习保护隐私的训练方法在小联盟内部训练一个模型，具体训练操作如下文a-f所示，流程图描述见图1。
（a) 根据数据集特征，联邦服务器选择一个合适的机器学习模型并初始化模型参数，然后将此初始模型发送给小联盟内各公司。
（b）小联盟内各公司利用批量梯度下降法以及其拥有的数据集反复训练本地模型。若某公司拥有的数据集太大，一次迭代需花费的训练时间太长，可通过蒙特卡洛取样法：随机选取一部分数据进行本地模型迭代更新，达到增加本地迭代次数又不影响本地模型准确率的效果。
（c）在训练一定时间 后，联邦服务器开始收集各公司的本地模型或模型参数，公司拥有的本地数据集不会被传输到联邦服务器。
（d）联邦服务器将收集到的各本地模型参数按一定比例（比如取平均值或按照本地数据集大小进行加权平均）进行聚合，获得并更新联邦模型参数。
（e）聚合完成后，联邦服务器将更新的联邦模型分发给所有小联盟内公司。公司利用本地数据集和刚分发到的联邦模型开启新一轮的本地训练，并于时间 后将本地模型或参数发送给联邦服务器进行下一次聚合。
（f）反复进行上述的本地训练-传输模型或参数给联邦服务器-联邦模型更新参数-分发给各公司-各公司继续进行本地训练，直至联邦服务器处的联邦模型收敛。
（2.1.2）将小联盟的联邦学习模型在测试集测试，计算此模型的预测准确率,记为 。
（2.1.3）用上述联邦学习模型训练方法在新的小联盟 ，即上述小联盟 去除公司 后的联盟，训练一个新的联邦学习模型，并在测试集测试新模型的预测准确率，记为 。
（2.1.4）获得此公司 对于联盟 的边际贡献： 。
（2.1.5）将此公司 与联盟内任意其他公司组成所有可能的小联盟，按上述方法计算公司 对此小联盟的边际贡献。
（2.1.6）公司 的数据价值--夏普利值 ，即为其对联盟内所有可能的小联盟的边际贡献的平均值，用夏普利值公式表示即为： ，此处 表示所有公司组成的大联盟， 表示某联盟的公司数量。
（2.2）若为移动用户或物联网设备的联邦学习场景，计算某个用户 （以下用户均可换为物联网设备）提供的数据价值即夏普利值的方法为：先计算每轮本地训练的分步夏普利值，将此用户所有轮的分步夏普利值相加作为用户 的最终夏普利值。文字描述详见下文2.2.1-2.2.2，表格描述见图3。
(2.2.1)计算用户 在每一轮本地训练 的分步夏普利值方法如下文a-g所示。
（a） 若用户 因不满足电力、通讯等条件未参与此轮训练，将其本轮分步夏普利值 记为0.
（b）若用户满足条件参与了本地训练轮 ，设置初始联邦机器学习模型为经过上一轮本地训练后联邦所得模型。（若这是第一轮本地训练，则可任意设置初始模型参数。）
（c）将此用户与参与了 轮联邦学习的任意其他一个或多个用户（记为 ）组成一个小联盟，记为 。利用（2）中描述的联邦学习训练方法，初始联邦模型及其参数采用（2.2.1b)中设置的初始联邦模型，在小联盟内部训练一个模型，并测试此模型在测试集的预测准确率，记为 。
（d）利用（2）中描述的联邦学习训练方法， 采用（2.2.1.b)中设置的初始联邦模型，在新的小联盟 ，即上述小联盟 去除用户 后的联盟，训练一个新的联邦学习模型，并在测试集测试新模型的预测准确率，记为 。
（e）获得此用户 对于联盟 的边际贡献： 。
（f）将此用户 与参与了 轮本地训练的任意其他用户组成所有可能的小联盟，按上述方法计算用户 对此小联盟的边际贡献。若参与此训练轮的用户数量过大，可采用蒙特卡洛取样法：随机选取部分参与本轮训练的用户，只计算用户 对这部分用户组成的所有可能小联盟的边际贡献，达到减少计算用户 在 轮分步夏普利值所需时间，又不影响其分步夏普利值计算结果准确性的效果。
（g）用户 在 轮的分步夏普利值 ，即为其对本轮中所有可能组成的小联盟的边际贡献的平均值，（若采用了蒙特卡洛取样法，则计算用户 对随机采样的用户组成的所有可能的联盟的边际贡献的平均值）用夏普利值公式表示即为： ，此处 表示参与了 轮本地训练的所有用户组成的大联盟， 表示某联盟的用户数量。
(2.2.2)按照（2.2.1）中描述的方法计算用户 在所有本地训练轮次的分步夏普利值。用户 的数据贡献，即其最终夏普利值为其在所有本地训练轮的分步夏普利值的总和，用公式表示即为 。
（3）令参与联邦学习的公司或移动设备用户 上报其本地模型训练的资源成本，记为 。
（4）记联邦学习参与方 通过联邦学习模型所获收入为 ，利润为 。因此参与方 的利润满足 。根据公平分配的要求，利润 与任意其他联邦学习参与方 通过模型所获利润 应满足比例： 。此比例意味着任意联邦学习参与方 （ ）的数据贡献即利润满足可公平衡量数据价值的夏普利值的比例，因此利润分配方案是公平的。
（5）记本次联邦学习所得模型赚取的收入为 ， 。化简（4）中比例可得联邦学习参与方 在本次学习中应分得的利润 满足 。值得注意的是，若此次联邦学习整体而言是盈利的，即 ，参与方 在联邦学习中获得的利润 是非负数，因此该利润分配方案能有效激励训练方参与联邦学习。

## 4、本发明创新的关键点和想保护的技术方案是什么？
<!-- 撰写指导：
与已知的现有技术相比，本发明会有一些与其不同的关键区别点，这些关键区别点通常会带来明显的或重要的技术效果，这里请说明哪些点是关键区别点，并将这些点可能的组合方案都列举出来。 -->

本发明想保护的核心技术方案是：
针对不同联邦学习应用场景下的参与方数据价值的夏普利值计算方法，以及综合考虑联邦学习参与方模型训练所消耗的资源成本的联邦学习模型所获利润的公平分配方法。

本发明与现有方法相比具有如下优点和创新点：
第一，现有联邦学习相关技术发明专利主要聚焦于如何设计并优化模型训练方法，以提高训练效率或更好地保护隐私，缺乏对模型所得收益在参与方中的公平分配方法，因而无法有效激励各方参与加入联邦贡献其本地数据和计算等资源。本发明所提出了一种公平分配联邦学习模型收益的方案，弥补了这方面的空白。
第二，现有利用夏普利值衡量机器学习参与方贡献程度的方法在联邦学习场景中只能衡量参与方本地的数据贡献，无法体现参与方在本地模型训练过程中的能耗和时间等资源成本消耗，因而无法准确衡量联邦学习各参与方的贡献程度以实现利润分配的公平性。本发明同时考虑了联邦学习各参与方的数据贡献和资源消耗，通过结合夏普利值和训练成本，达到全面准确衡量各方贡献，实现更为公平的利润分配。
第三，现有基于夏普利值计算方法来衡量参与方数据价值的方法需要所有参与方在联邦学习的每轮训练中均参与，该方法适用于面向公司机构的联邦学习场景，但无法有效衡量和计算面向移动用户或物联网设备场景中，由于通信带宽和计算资源等限制用户无法每轮参与联邦学习训练的场景下参与方的数据贡献价值。本发明引入改进的针对每轮参与联邦学习参与方的分步夏普利值方法来有效的衡量各参与方的数据贡献，以实现该联邦学习场景下的公平利润分配。

## 5、本发明可能的变更设计方向或者变形方案？
<!-- 撰写指导：
从整体考虑，是否有整体的替代或变形方案，或者对核心技术特征的替代或变形方案；主要根据本发明体现出来的设计思路，别人能不能想到其他的整体的替代方案来实现；
从另一个角度讲：考虑授权后，站在竞争对手的角度可能提出的回避设计方案。 -->

（1）提出降低计算夏普利值复杂度的求解方法来衡量参与方的数据贡献。
（2）在面向公司机构联邦学习场景中，当资源消耗成本与数据价值贡献相差较大时，忽略参与方资源成本消耗，只按照数据贡献的比例进行分配利润。

## 6、发明人补充的其他观点和思路
<!-- 撰写指导：
除1－5部分还需要补充的部分。 -->

## 7、图及说明
<!-- 撰写指导：
1、交底书部分中未提及的附图标记不得在附图中出现，附图中未出现的附图标记不得在交底书文字中提及；
2、附图中除必须词语（如电路或程序的方框图、流程图、波形图等）外，尽量不要包含有其它文字注释；
3、同一部件或部分的附图标记在前后几幅附图中应一致，同一附图标记不得表示不同的部件或部分；
4、附图集中放在交底书文字之后；
5、附图中，零部件的编号可以用数字表示，也可以直接用零部件的名称来表示。 -->
正文：

图1为联邦学习流程图。
图2为各公司或机构夏普利值计算方式流程图。
图3为各移动用户或物联网设备夏普利值计算方式表格。
图4为本发明提出的联邦学习利润公平分配方式流程图。
