# 专利底书_用于安卓和iOS的跨平台联邦学习系统

## 1、详细介绍技术背景，并描述已有的与本发明相关的现有技术，说明现有技术的缺点

随着国家对数据隐私保护越发重视，传统的将所有用户数据汇聚到中心训练端的机器学习范式将不再合规，联邦学习作为一种保护隐私的分布式机器学习范式，获得了大量关注。联邦学习不需将用户数据集中，参与方只需反复进行本地模型训练，将模型参数发送给中心端直至收敛即可完成训练。

现有的联邦学习研究主要基于桌面计算机模拟，这可能忽略了实际应用中的约束条件。为了在实际环境中优化联邦学习算法设计，亟需一种实用的移动联邦学习系统，利用真实用户数据。然而，目前可用的移动联邦学习系统存在以下局限：

1. 缺乏跨平台的设备上训练和模型聚合能力。
2. 无法最大限度地控制用户设备上的联邦学习过程。
3. 数据科学家在开发移动联邦学习模型时面临开发环境的不熟悉。

## 2、本发明摘要：针对现有技术存在的技术问题，提出本发明的基本方案或基本思路，以及本发明针对现有技术所具备的整体技术效果

本发明提出一种专为在安卓和iOS设备上进行跨平台联邦学习研究而设计的联邦学习系统。本发明通过支持模型转换、硬件加速训练和跨平台模型聚合，解决了现有移动联邦学习系统的局限性。具体而言，本发明包括以下主要功能：

1. **跨平台联邦学习模型管道**：提供统一的训练API，实现Python模型转换为安卓的TensorFlow Lite和iOS的Core ML格式。
2. **灵活的MLOps生产流程**：在生产环境中，支持模型的持续交付和训练，利用自托管后端服务器协调安卓和iOS客户端设备。
3. **跨平台模型聚合**：确保模型参数表示的统一，解决在TensorFlow Lite和Core ML中的参数获取和设置问题。

通过这些功能，本发明支持在安卓和iOS客户端设备上进行联邦学习，协调统一后端服务器的管理，实现联邦模型的公平有效聚合。

## 3、本发明技术方案的详细阐述

### 3.1 详细技术方案

#### 3.1.1 跨平台联邦学习模型管道

1. **模型转换**：将Python模型转换为TensorFlow Lite和Core ML格式。利用标准化模型格式，包括四个必要的联邦学习方法（训练、推理、参数获取、参数恢复）。
2. **统一训练API**：提供TensorFlow Lite训练包和Core ML训练包，支持在安卓和iOS设备上利用GPU和NPU加速训练，并暴露统一的API用于参数获取和设置、模型拟合和评估。

#### 3.1.2 灵活的MLOps生产流程

1. **持续跨平台模型交付**：客户端通过模型请求从后端获取适合其平台和训练数据类型的模型。
2. **可定制的持续联邦学习训练**：支持多并行联邦学习训练会话，通过联邦学习服务器设置，允许新模型立即开始训练，而不影响现有训练会话。

### 3.2 技术效果

本发明提供了一种有效的跨平台联邦学习解决方案，解决了移动设备上跨平台训练和聚合的挑战，提高了模型交付和训练的灵活性，并在实际场景中验证了其有效性。

### 3.3 实现方式

1. **模型转换和训练**：利用ProtoBuf定义文件生成的Swift代码，修改Core ML模型的底层表示以解决参数设置限制。
2. **跨平台聚合**：通过标准化模型参数表示，实现了TensorFlow Lite和Core ML模型参数的统一处理，确保聚合的无缝进行。
3. **MLOps流程**：利用Django后端和Flower 联邦学习框架，管理联邦学习训练的调度和评估。

## 4、本发明创新的关键点和想保护的技术方案是什么？

### 4.1 关键区别点

1. **跨平台联邦学习模型管道**：实现了Python模型到TensorFlow Lite和Core ML格式的转换和统一训练API。
2. **灵活的MLOps生产流程**：支持模型的持续交付和多并行联邦学习训练会话。
3. **跨平台模型聚合**：解决了在TensorFlow Lite和Core ML中的参数获取和设置问题，实现了统一的模型参数表示和处理。

### 4.2 创新点

1. **首次实现了跨平台联邦学习系统的模型转换和统一训练API**。
2. **提供了灵活的MLOps生产流程，支持持续模型交付和训练**。
3. **解决了跨平台模型参数表示的统一问题，实现了无缝聚合**。

## 5、本发明可能的变更设计方向或者变形方案？

1. **降低计算复杂度的方法**：优化模型转换和参数处理的算法，以提高效率。
3. **其他跨平台框架支持**：扩展支持其他移动平台和机器学习框架，以增强系统的适用性。
