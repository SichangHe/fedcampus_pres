# 专利底书_用于Android和iOS的跨平台联邦学习系统

## 1、详细介绍技术背景，并描述已有的与本发明相关的现有技术，说明现有技术的缺点

随着国家对数据隐私保护越发重视，传统的将所有用户数据汇聚到中心训练端的机器学习范式将不再合规，联邦学习(Federated Learning, FL)作为一种保护隐私的分布式机器学习范式，获得了大量关注。FL不需将用户数据集中，参与方只需反复进行本地模型训练，将模型参数发送给中心端直至收敛即可完成训练。

现有的FL研究主要基于桌面计算机模拟，这可能忽略了实际应用中的约束条件。为了在实际环境中优化FL算法设计，亟需一种实用的移动FL系统，利用真实用户数据。然而，目前可用的移动FL系统存在以下局限：

1. 缺乏跨平台的设备上训练和模型聚合能力。
2. 无法最大限度地控制用户设备上的FL过程。
3. 数据科学家在开发移动FL模型时面临开发环境的不熟悉。

例如，专利CN113762530A仅关注FL模型的训练方式和隐私保护策略，缺乏对FL参与方贡献衡量方法的探究。专利CN112949865A通过模型梯度信息衡量贡献，但无法满足不同参与方之间的公平性。专利CN111461341A虽然利用夏普利值方法衡量机器学习中的数据源贡献，但无法补偿FL中本地模型训练所消耗的资源成本。此外，针对用户设备的FL场景，由于受通信带宽和计算资源限制，无法确保所有设备每轮参与FL，缺乏针对该场景的数据价值衡量方法。

## 2、本发明摘要：针对现有技术存在的技术问题，提出本发明的基本方案或基本思路，以及本发明针对现有技术所具备的整体技术效果

本发明提出并公开了一种名为FEDKIT的FL系统，专为在Android和iOS设备上进行跨平台FL研究而设计。FEDKIT通过支持模型转换、硬件加速训练和跨平台模型聚合，解决了现有移动FL系统的局限性。具体而言，FEDKIT包括以下主要功能：

1. **跨平台FL模型管道**：提供统一的训练API，实现Python模型转换为Android的TensorFlow Lite（TFLite）和iOS的Core ML格式。
2. **灵活的MLOps生产流程**：在生产环境中，支持模型的持续交付和训练，利用自托管后端服务器协调Android和iOS客户端设备。
3. **跨平台模型聚合**：确保模型参数表示的统一，解决在TFLite和Core ML中的参数获取和设置问题。

通过这些功能，FEDKIT支持在Android和iOS客户端设备上进行FL，协调统一后端服务器的管理，实现联邦模型的公平有效聚合。

## 3、本发明技术方案的详细阐述

### 3.1 详细技术方案

#### 3.1.1 跨平台FL模型管道

1. **模型转换**：将Python模型转换为TFLite和Core ML格式。利用标准化模型格式，包括四个必要的FL方法（训练、推理、参数获取、恢复）。
2. **统一训练API**：提供TFLite Trainer和Core ML Trainer，支持在Android和iOS设备上利用GPU和NPU加速训练，并暴露统一的API用于参数获取和设置、模型拟合和评估。

#### 3.1.2 灵活的MLOps生产流程

1. **持续跨平台模型交付**：客户端通过模型请求从后端获取适合其平台和训练数据类型的模型。
2. **可定制的持续FL训练**：支持多并行FL训练会话，通过FL服务器设置，允许新模型立即开始训练，而不影响现有训练会话。

### 3.2 技术效果

本发明提供了一种有效的跨平台FL解决方案，解决了移动设备上跨平台训练和聚合的挑战，提高了模型交付和训练的灵活性，并在实际场景中验证了其有效性。

### 3.3 实现方式

1. **模型转换和训练**：利用ProtoBuf定义文件生成的Swift代码，修改Core ML模型的底层表示以解决参数设置限制。
2. **跨平台聚合**：通过标准化模型参数表示，实现了TFLite和Core ML模型参数的统一处理，确保聚合的无缝进行。
3. **MLOps流程**：利用Django后端和Flower FL框架，管理FL训练的调度和评估。

## 4、本发明创新的关键点和想保护的技术方案是什么？

### 4.1 关键区别点

1. **跨平台FL模型管道**：实现了Python模型到TFLite和Core ML格式的转换和统一训练API。
2. **灵活的MLOps生产流程**：支持模型的持续交付和多并行FL训练会话。
3. **跨平台模型聚合**：解决了在TFLite和Core ML中的参数获取和设置问题，实现了统一的模型参数表示和处理。

### 4.2 创新点

1. **首次实现了跨平台FL系统的模型转换和统一训练API**。
2. **提供了灵活的MLOps生产流程，支持持续模型交付和训练**。
3. **解决了跨平台模型参数表示的统一问题，实现了无缝聚合**。

## 5、本发明可能的变更设计方向或者变形方案？

1. **降低计算复杂度的方法**：优化模型转换和参数处理的算法，以提高效率。
2. **忽略资源成本**：在资源消耗成本与数据价值贡献相差较大时，仅依据数据贡献比例进行利润分配。
3. **其他跨平台框架支持**：扩展支持其他移动平台和机器学习框架，以增强系统的适用性。
